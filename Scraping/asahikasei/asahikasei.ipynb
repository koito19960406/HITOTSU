{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1599987072982",
   "display_name": "Python 3.7.4 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "import datetime\n",
    "import csv\n",
    "import openpyxl\n",
    "from openpyxl import Workbook\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Asahikasei:\n",
    "    # prepare the input date\n",
    "    def __init__(self, year, month, day):\n",
    "        self.output_date=int(str(year)+str(month)+str(day))\n",
    "\n",
    "    # scrape info about: name of the product and url\n",
    "    def scrape(self):\n",
    "        #open chrome in incognito mode\n",
    "        options = webdriver.ChromeOptions()\n",
    "        options.add_argument(' -- incognito')\n",
    "        browser = webdriver.Chrome(chrome_options=options)\n",
    "\n",
    "        # deal with the first \"medical staff?\" question\n",
    "        browser.get('http://www.asahi-kasei.co.jp/medical/dialysis/product/')\n",
    "\n",
    "        # wait for browser to open for 10 sec\n",
    "        timeout = 10\n",
    "        try:\n",
    "            WebDriverWait(browser, timeout).until(\n",
    "            EC.visibility_of_element_located(\n",
    "            (By.XPATH, '//*[@id=\"yesButton\"]')\n",
    "            )\n",
    "            )\n",
    "        except TimeoutException:\n",
    "            print('Timed Out Waiting for page to load')\n",
    "            browser.quit()\n",
    "\n",
    "        # Click the yes button\n",
    "        login_btn=browser.find_element_by_xpath('//*[@id=\"yesButton\"]')\n",
    "        login_btn.click()\n",
    "        browser.implicitly_wait(3)\n",
    "\n",
    "        # Get info\n",
    "        # Go to the list\n",
    "        product_list=browser.find_element_by_xpath('//*[@id=\"mainArea02\"]').find_elements_by_css_selector('ul.linkULA01>li')\n",
    "        # Go through the list\n",
    "        result=[]\n",
    "        # Check if the news element is nth number, and if n is an odd number skip.\n",
    "        for product in product_list:\n",
    "            # Get link and title\n",
    "            product_url=product.find_element_by_css_selector('a').get_attribute('href')\n",
    "            product_name=product.find_element_by_css_selector('a').text.strip()\n",
    " \n",
    "            # Append the info to the list\n",
    "            result.append([product_name, product_url])\n",
    "\n",
    "        # close the browser        \n",
    "        browser.quit()\n",
    "        return result\n",
    "\n",
    "    # store the list into CSV if there is no csv. If not, load the csv and check if there's any product thats not in the older csv.\n",
    "    def get_new_product(self):\n",
    "        try:\n",
    "        # load an old list of product and convert it to a dataframe\n",
    "            column_names=['product_name','product_url']\n",
    "            df_product_list=pd.read_csv(\"Asahikasei_product_list.csv\",names=column_names)\n",
    "\n",
    "            # get result\n",
    "            result = self.scrape()\n",
    "            \n",
    "\n",
    "            # Find if there's any new products\n",
    "            new_product_list=[]\n",
    "            for product in result:\n",
    "                if not(df_product_list['product_name'].isin([product[0]]).any()):\n",
    "                    new_product_list.append(product)\n",
    "            \n",
    "            # check if there's any new product. If so, append them to the existing product list\n",
    "            if len(new_product_list)>0:\n",
    "                with open('Asahikasei_product_list.csv', 'a') as csvfile:\n",
    "                    writer = csv.writer(csvfile)\n",
    "                    for i in range(len(new_product_list)):\n",
    "                        writer.writerow([new_product_list[i][0],  \n",
    "                                        new_product_list[i][1]])\n",
    "\n",
    "            # return a list of new products\n",
    "            return new_product_list\n",
    "        \n",
    "        # if there's no such file, create a new file \n",
    "        except FileNotFoundError:\n",
    "            with open('Asahikasei_product_list.csv','w') as csvfile:\n",
    "                result = self.scrape()\n",
    "                result_len=len(result)\n",
    "                writer = csv.writer(csvfile)\n",
    "                for i in range(result_len):\n",
    "                    writer.writerow([result[i][0],  \n",
    "                                    result[i][1]])\n",
    "            # return an empty list\n",
    "            return []\n",
    "\n",
    "    # store new products' info into csv\n",
    "    def to_csv(self):\n",
    "        # get new products\n",
    "        new_product_list=self.get_new_product()\n",
    "        new_product_list_len = len(new_product_list)\n",
    "\n",
    "        # check if the result is empty\n",
    "        if new_product_list_len == 0:\n",
    "            return\n",
    "\n",
    "        # get row number\n",
    "        # try to open the csv file\n",
    "        try:\n",
    "            with open('product_info.csv') as csvfile:\n",
    "                reader = csv.reader(csvfile)\n",
    "\n",
    "        # if there's no such file, create a new file \n",
    "        except FileNotFoundError:\n",
    "            with open('product_info.csv','w') as csvfile:\n",
    "                pass\n",
    "        \n",
    "        # add new data\n",
    "        with open('product_info.csv', 'a') as csvfile:\n",
    "            writer = csv.writer(csvfile)\n",
    "            for i in range(new_product_list_len):\n",
    "                writer.writerow([self.output_date, \n",
    "                                '血液浄化', \n",
    "                                '', \n",
    "                                '',\n",
    "                                '',\n",
    "                                '旭化成メディカル', \n",
    "                                '新製品',\n",
    "                                new_product_list[i][0], \n",
    "                                new_product_list[i][1], \n",
    "                                '1'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if __name__=='__main__':\n",
    "    year=2020\n",
    "    month=9\n",
    "    day=13\n",
    "    asahikasei=Asahikasei(year,month,day)\n",
    "    asahikasei.to_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}